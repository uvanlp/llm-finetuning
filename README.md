# LLM Finetuning 

**Goal**: provide a codebase to easily fine-tune some open-source LLMs and reproduce the results. 

So far, the codebase supports 

- Fine-tuning algorithms offered by the [PEFT](https://github.com/huggingface/peft) package
  - LoRA
- Open-source LLM families from Hugging Face
  - Llama 2
  - Falcon
  - Flan-T5
- In-context learning

---

## Environment Setup

We provide the instructions for setting up the environment for 

- [UVA Rivanna](https://www.notion.so/Environment-Configuration-on-Rivanna-5cb1f289049146e6ae63546031df6498?pvs=4), and 
- [UVA CS Servers]()

---

## A simple example

Please refer to the simple example in `demo.py` for how to use this codebase for training and test.

